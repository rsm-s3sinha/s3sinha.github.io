[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Shefali Sinha",
    "section": "",
    "text": "Hello,\nMy name is Shefali and I am a graduate student at Rady School of Management.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Shefali Sinha’s Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "My Main Project\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nShefali Sinha\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nShefali Sinha\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nKey Drivers Analysis\n\n\n\n\n\n\nYour Name\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMultinomial Logit Examples\n\n\n\n\n\n\nShefali Sinha\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project 1/index.html",
    "href": "projects/project 1/index.html",
    "title": "My Main Project",
    "section": "",
    "text": "I like to plot data.\n\n\nI also analyze data."
  },
  {
    "objectID": "projects/project 1/index.html#sub-header",
    "href": "projects/project 1/index.html#sub-header",
    "title": "My Main Project",
    "section": "",
    "text": "I also analyze data."
  },
  {
    "objectID": "hw1_questions.html",
    "href": "hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#introduction",
    "href": "hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#data",
    "href": "hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "hw1_questions.html#experimental-results",
    "href": "hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "hw1_questions.html#simulation-experiment",
    "href": "hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "projects/project 1/hw1_questions.html",
    "href": "projects/project 1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project 1/hw1_questions.html#introduction",
    "href": "projects/project 1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project 1/hw1_questions.html#data",
    "href": "projects/project 1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n# Import libraries\nimport pandas as pd\nfrom scipy import stats\nimport statsmodels.api as sm\n\n# Load the data\nkarlan_list = pd.read_stata('../../files/karlan_list_2007.dta')\n\n# Summary of Karlan List\nkarlan_list.describe()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168560\n0.135868\n0.103039\n0.378105\n22027.316665\n0.193405\n0.186599\n0.258633\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper).\n\n# Drop the missing value\n\nkarlan_list_cleaned = karlan_list.dropna(subset=['mrm2'])\n\n# Separating the groups\n\ncontrol = karlan_list_cleaned[karlan_list_cleaned['control'] == 1]['mrm2']\n\ntreatment = karlan_list_cleaned[karlan_list_cleaned['treatment'] == 1]['mrm2']\n\n# T-test\nt_stat, p_value = stats.ttest_ind(control, treatment, equal_var = False)\n\n# Linear Regression\nX = sm.add_constant(karlan_list_cleaned['treatment'])\ny = karlan_list_cleaned['mrm2']\nmodel = sm.OLS(y, X).fit()\nsummary = model.summary()\n\n# Output\nprint(f\"T-test Statistics: {t_stat}, P-value: {p_value}\")\n\nprint(summary)\n\nT-test Statistics: -0.11953155228177251, P-value: 0.9048549631450832\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Tue, 30 Apr 2024   Prob (F-statistic):              0.905\nTime:                        22:07:38   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
  },
  {
    "objectID": "projects/project 1/hw1_questions.html#experimental-results",
    "href": "projects/project 1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Calculating the proportion for 'gave'\n\ncontrol_proportion = karlan_list[karlan_list['control'] == 1]['gave'].mean()\n\ntreatment_proportion = karlan_list[karlan_list['treatment'] == 1]['gave'].mean()\n\n# Values for plotting\nproportions = [control_proportion, treatment_proportion]\ngroup_labels = ['Control', 'Treatment']\n\n# Creating a bar plot\nplt.figure(figsize = (8, 6))\nplt.bar(group_labels, proportions, color = ['blue', 'red'])\n\n# Set y-axis limits and ticks for better visibility if proportions are low\nmax_proportion = max(proportions)\nplt.ylim(0, max_proportion * 1.2)  # Extend y-axis a bit above the max value for visual comfort\nplt.yticks(np.arange(0, max_proportion * 1.2, step=max_proportion / 5))\n\n\n# Adding labels and title\nplt.ylabel('Proportion Who Donated')\nplt.title('Proportion of Donations by Group')\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\n\n# Running a T-test\ncontrol_donations = karlan_list[karlan_list['control'] == 1]['gave']\ntreatment_donations = karlan_list[karlan_list['treatment'] == 1]['gave']\n\nt_stat, p_value = stats.ttest_ind(control_donations, treatment_donations, equal_var = False)\n\n# Running a Bivariate Linear Regression\nX = sm.add_constant(karlan_list['treatment'])\ny = karlan_list['gave']\n\nmodel = sm.OLS(y, X).fit()\nsummary = model.summary()\n\n# Output of T-test\nprint(f\"T-test statistic: {t_stat}, P-value: {p_value}\\n\")\n\n# Output of regression result\nprint(summary)\n\nT-test statistic: -3.2094621908279835, P-value: 0.0013309823450914173\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Tue, 30 Apr 2024   Prob (F-statistic):            0.00193\nTime:                        22:07:38   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n# Preparing data for Probit Regression\nX = sm.add_constant(karlan_list['treatment'])\ny = karlan_list['gave']\n\n# Initialize and fit the Probit model\nprobit_model = sm.Probit(y, X).fit()\n\ncoef = probit_model.params['treatment']\np_value = probit_model.pvalues['treatment']\n\nprint(probit_model.summary)\nprint('coef: ', coef)\nprint('p_value: ', p_value)\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n&lt;bound method BinaryResults.summary of &lt;statsmodels.discrete.discrete_model.ProbitResults object at 0xffff735258d0&gt;&gt;\ncoef:  0.08678462244746639\np_value:  0.0018523990147768265\n\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\n\n# T-test between 1:1 match rate and 2:1 match rate\ngave_ratio1 = karlan_list[karlan_list['ratio'] == 1]['gave']\ngave_ratio2 = karlan_list[karlan_list['ratio2'] == 1]['gave']\nt_stat_1_vs_2, p_value_1_vs_2 = stats.ttest_ind(gave_ratio1, gave_ratio2, equal_var=False)\n\n# T-test between 1:1 match rate and 3:1 match rate\ngave_ratio3 = karlan_list[karlan_list['ratio3'] == 1]['gave']\nt_stat_1_vs_3, p_value_1_vs_3 = stats.ttest_ind(gave_ratio1, gave_ratio3, equal_var=False)\n\n# T-test between 2:1 match rate and 3:1 match rate\nt_stat_2_vs_3, p_value_2_vs_3 = stats.ttest_ind(gave_ratio2, gave_ratio3, equal_var=False)\n\n# Output the results\nprint(f\"1:1 vs 2:1 T-test statistic: {t_stat_1_vs_2}, P-value: {p_value_1_vs_2}\")\nprint(f\"1:1 vs 3:1 T-test statistic: {t_stat_1_vs_3}, P-value: {p_value_1_vs_3}\")\nprint(f\"2:1 vs 3:1 T-test statistic: {t_stat_2_vs_3}, P-value: {p_value_2_vs_3}\")\n\n1:1 vs 2:1 T-test statistic: -0.965048975142932, P-value: 0.33453078237183076\n1:1 vs 3:1 T-test statistic: -1.0150174470156275, P-value: 0.31010856527625774\n2:1 vs 3:1 T-test statistic: -0.05011581369764474, P-value: 0.9600305476940865\n\n\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\n\n# T-test on the amount donated between control and treatment groups\namount_control = karlan_list[karlan_list['control'] == 1]['amount']\namount_treatment = karlan_list[karlan_list['treatment'] == 1]['amount']\nt_stat, p_value = stats.ttest_ind(amount_control, amount_treatment, equal_var=False)\n\n# Bivariate Linear Regression of amount on treatment status\nX = sm.add_constant(karlan_list['treatment'])\ny = karlan_list['amount']\nmodel = sm.OLS(y, X).fit()\n\n# Print the t-test results\nprint(f\"T-test statistic: {t_stat}, P-value: {p_value}\")\n\nprint(model.summary())\n\nT-test statistic: -1.9182618934467577, P-value: 0.05508566528918335\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Tue, 30 Apr 2024   Prob (F-statistic):             0.0628\nTime:                        22:07:38   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\n\n# Filter the data to only include individuals who made a donation\ndonors = karlan_list[karlan_list['amount'] &gt; 0]\n\n# Perform a T-test on the donation amount between the control and treatment groups within donors\namount_control = donors[donors['control'] == 1]['amount']\namount_treatment = donors[donors['treatment'] == 1]['amount']\nt_stat, p_value = stats.ttest_ind(amount_control, amount_treatment, equal_var=False)\n\n# Print the t-test results for donors\nprint(f\"T-test statistic for donors: {t_stat}, P-value for donors: {p_value}\")\n\n# Perform a Bivariate Linear Regression of donation amount on treatment status for donors\nX_donors = sm.add_constant(donors['treatment'])  # Add a constant for the intercept\ny_donors = donors['amount']\namount_model_donors = sm.OLS(y_donors, X_donors).fit()\n\n# Print the summary of the regression model for donors\nprint(amount_model_donors.summary())\n\nT-test statistic for donors: 0.5846089794983359, P-value for donors: 0.5590471865673547\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Tue, 30 Apr 2024   Prob (F-statistic):              0.561\nTime:                        22:07:38   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\n\n# Separate the donors into treatment and control groups\ntreatment_donors = donors[donors['treatment'] == 1]\ncontrol_donors = donors[donors['control'] == 1]\n\n# Calculate the sample averages for the treatment and control groups\navg_treatment_donation = treatment_donors['amount'].mean()\navg_control_donation = control_donors['amount'].mean()\n\n# Plot histograms\nfig, ax = plt.subplots(1, 2, figsize=(14, 7))\n\n# Treatment group histogram\nax[0].hist(treatment_donors['amount'], bins=30, color='blue', alpha=0.7)\nax[0].axvline(avg_treatment_donation, color='red', linestyle='dashed', linewidth=2)\nax[0].set_title('Treatment Group Donation Amounts')\nax[0].set_xlabel('Donation Amount')\nax[0].set_ylabel('Frequency')\nax[0].annotate(f'Average: ${avg_treatment_donation:.2f}', \n               xy=(avg_treatment_donation, 5), \n               xytext=(avg_treatment_donation * 1.1, 25),\n               arrowprops=dict(facecolor='red', shrink=0.05))\n\n# Control group histogram\nax[1].hist(control_donors['amount'], bins=30, color='green', alpha=0.7)\nax[1].axvline(avg_control_donation, color='red', linestyle='dashed', linewidth=2)\nax[1].set_title('Control Group Donation Amounts')\nax[1].set_xlabel('Donation Amount')\nax[1].set_ylabel('Frequency')\nax[1].annotate(f'Average: ${avg_control_donation:.2f}', \n               xy=(avg_control_donation, 5), \n               xytext=(avg_control_donation * 1.1, 25),\n               arrowprops=dict(facecolor='red', shrink=0.05))\n\n# Show the plot\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/project 1/hw1_questions.html#simulation-experiment",
    "href": "projects/project 1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\nimport numpy as np\n\n# Set seed for reproducibility\nnp.random.seed(0)\n\n# Simulate draws for the control group and calculate the cumulative average\ncontrol_draws = np.random.choice(control_donors['amount'], size=100000, replace=True)\ncontrol_cumulative_avg = np.cumsum(control_draws) / np.arange(1, 100001)\n\n# Simulate draws for the treatment group and calculate the cumulative average\ntreatment_draws = np.random.choice(treatment_donors['amount'], size=10000, replace=True)\ntreatment_cumulative_avg = np.cumsum(treatment_draws) / np.arange(1, 10001)\n\n# Calculate the cumulative difference in means\ncumulative_diff_means = treatment_cumulative_avg[:10000] - control_cumulative_avg[:10000]\n\n# Plot the cumulative difference in means\nplt.figure(figsize=(12, 6))\nplt.plot(cumulative_diff_means, color='orange', lw=2)\nplt.axhline(y=avg_treatment_donation - avg_control_donation, color='red', linestyle='--', linewidth=1.5)\nplt.xlabel('Number of Draws')\nplt.ylabel('Cumulative Difference in Means')\nplt.title('Convergence of Cumulative Difference in Means Between Treatment and Control')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”\n\n# Set a seed for reproducibility\nnp.random.seed(0)\n\n# Assume we have the control and treatment amounts as numpy arrays\ncontrol_amounts = karlan_list[karlan_list['control'] == 1]['amount'].values\ntreatment_amounts = karlan_list[karlan_list['treatment'] == 1]['amount'].values\n\nsample_sizes = [50, 200, 500, 1000]\nsimulations = 1000\n\n# Initialize a plot\nfig, axs = plt.subplots(2, 2, figsize=(14, 10))\naxs = axs.flatten()  # Flatten the array of axes for easy iteration\n\n# True mean difference between treatment and control\ntrue_diff = np.mean(treatment_amounts) - np.mean(control_amounts)\n\n# Iterate over different sample sizes\nfor i, sample_size in enumerate(sample_sizes):\n    # Store the average differences\n    avg_diffs = []\n    \n    for _ in range(simulations):\n        # Draw random samples from control and treatment\n        control_sample = np.random.choice(control_amounts, sample_size, replace=True)\n        treatment_sample = np.random.choice(treatment_amounts, sample_size, replace=True)\n        \n        # Calculate the average difference for this simulation\n        avg_diff = np.mean(treatment_sample) - np.mean(control_sample)\n        avg_diffs.append(avg_diff)\n    \n    # Plot the histogram of average differences for this sample size\n    axs[i].hist(avg_diffs, bins=30, color='skyblue', edgecolor='black')\n    axs[i].axvline(true_diff, color='red', linestyle='dashed', linewidth=2)\n    axs[i].set_title(f'Sample Size: {sample_size}')\n    axs[i].set_xlabel('Average Difference in Donation Amount')\n    axs[i].set_ylabel('Frequency')\n\n# Add a main title and adjust layout\nplt.suptitle('Histograms of Average Differences Between Treatment and Control')\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust the rectangle to prevent overlap of the main title\nplt.show()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "projects/project 1/hw2_questions.html",
    "href": "projects/project 1/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd\n\n# Load the data files\nblueprinty = pd.read_csv('../../files/blueprinty.csv')\n\nairbnb = pd.read_csv('../../files/airbnb.csv')\n\n\n\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize = (12, 6))\n\n# Customers\nplt.subplot(1, 2, 1)\nplt.hist(blueprinty[blueprinty['iscustomer'] == 1]['patents'], bins = 20, alpha = 0.7, color = 'blue')\nplt.title('Histogram of Patents - Customers')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\n\n# Non-Customers\nplt.subplot(1, 2, 2)\nplt.hist(blueprinty[blueprinty['iscustomer'] == 0]['patents'], bins = 20, alpha = 0.7, color = 'red')\nplt.title('Histogram of Patents - Non-Customers')\nplt.xlabel('Number of Patents')\n\nplt.tight_layout()\nplt.show()\n\n# Calculate and print the mean number of patents for both groups\nmean_patent_customers = blueprinty[blueprinty['iscustomer'] == 1]['patents'].mean()\nmean_patent_non_customers = blueprinty[blueprinty['iscustomer'] == 0]['patents'].mean()\nprint(f'The mean no. of patents for custoners: ', mean_patent_customers)\nprint(f'The mean no. of patents for non customers: ', mean_patent_non_customers)\n\n\n\n\n\n\n\n\nThe mean no. of patents for custoners:  4.091370558375634\nThe mean no. of patents for non customers:  3.6231772831926325\n\n\nFrom the histograms and the mean values of patents, we observe the following:\nHistograms: The distribution of patents for customers of Blueprinty (blue) shows a slightly more frequent occurrence of higher patent counts compared to non-customers (green). Both distributions are right-skewed, indicating that most firms have a relatively small number of patents, but some firms have significantly more.\nMean Number of Patents: Non-Customers: The mean number of patents is approximately 3.62. Customers: The mean number of patents is higher, at approximately 4.09. Blueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\n\n\nimport seaborn as sns\n\n# Plot distribution of regions by customer status\nplt.figure(figsize = (12, 6))\nplt.subplot(1, 2, 1)\nsns.countplot(data = blueprinty, x = 'region', hue = 'iscustomer', palette = 'Set1')\nplt.title('Distribution of Regions by Customer Status')\nplt.xticks(rotation = 45)\nplt.xlabel('Region')\nplt.ylabel('Count')\n\n# Plot distribution of age by customer status\nplt.subplot(1, 2, 2)\nsns.boxplot(data = blueprinty, x = 'iscustomer', y = 'age', palette = 'Set2')\nplt.title('Distribution of Age by Customer Status')\nplt.xlabel('Customer Status (0 = Non-Customer, 1 = Customer)')\nplt.ylabel('Age since Incorporation')\n\nplt.tight_layout()\nplt.show()\n\n/tmp/ipykernel_52250/2605947089.py:14: FutureWarning:\n\n\n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n\n\n\n\n\n\n\n\n\n\nFrom the analysis of age and regional distributions by customer status, we observe the following:\nAge Distribution: The boxplots show that firms using Blueprinty’s software (Is Customer = 1) tend to be younger compared to those not using the software. The mean age for customers is approximately 24.15 years, while for non-customers, it’s about 26.69 years. This indicates a systematic difference in the age of firms, where younger firms are more likely to be customers of Blueprinty.\nRegional Distribution: The count plots reveal some differences in regional preferences or presence for customers and non-customers. Some regions show a more pronounced disparity between the number of customers and non-customers, which could indicate regional market penetration or preferences affecting the adoption of Blueprinty’s software.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\nWhere:\n𝑒 is the base of the natural logarithm. 𝜆 is a positive real number. 𝑌 is the number of occurrences (a non-negative integer). 𝑌! denotes the factorial of 𝑌\nFor computational purposes, especially with larger datasets or larger values of 𝑌, it’s practical to work with the log-likelihood because it transforms products into sums, which are numerically more stable. The log-likelihood of the Poisson distribution is: \\[\n\\log L(\\lambda \\mid Y) = \\log(f(Y \\mid \\lambda)) = Y \\log(\\lambda) - \\lambda - \\log(Y!)\n\\]\n\n\n\nimport numpy as np\n\ndef poisson_loglikelihood(lambda_, Y):\n    # Ensure Y is an array for vector operations\n    Y = np.asarray(Y)\n    log_factorial_Y = np.log(np.arange(1, Y.max() + 1)).cumsum()\n\n    # Compute the log-likelihood\n    log_likelihood = np.sum(Y * np.log(lambda_) - lambda_ - np.where(Y &gt; 0, log_factorial_Y[Y - 1], 0))\n    return log_likelihood\n\n# Example use of the function with hypothetical lambda and Y\nlambda_example = 3.5  # example lambda value\nY_example = [0, 2, 3, 1, 0]  # example data points\n\n# Calculate the log-likelihood\nlog_likelihood_value = poisson_loglikelihood(lambda_example, Y_example)\nprint(\"Log-likelihood:\", log_likelihood_value)\n\nLog-likelihood: -12.468328838815792\n\n\nUsing likelihood function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y)\n\n# Extract the 'patents' column from the blueprinty DataFrame for use as Y\nY_patents = blueprinty['patents'].values\n\n# Define a range of lambda values for plotting\nlambda_values = np.linspace(0.1, 10, 400)\n\n# Compute log-likelihood values for each lambda\nlog_likelihood_values = [poisson_loglikelihood(lmbda, Y_patents) for lmbda in lambda_values]\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(lambda_values, log_likelihood_values, label='Log-Likelihood', color='blue')\nplt.title('Log-Likelihood of Poisson Model for Various Lambda Values')\nplt.xlabel('Lambda (λ)')\nplt.ylabel('Log-Likelihood')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFinding the MLE by optimizing the likelihood function with optim() in R or sp.optimize() in Python\n\nfrom scipy.optimize import minimize\n\n# Define the negative of the log-likelihood function since we need to minimize it\ndef negative_poisson_loglikelihood(lambda_, Y):\n    Y = np.asarray(Y)\n    log_factorial_Y = np.log(np.arange(1, Y.max() + 1)).cumsum()\n    return -np.sum(Y * np.log(lambda_) - lambda_ - np.where(Y &gt; 0, log_factorial_Y[Y - 1], 0))\n\n# Initial guess for lambda\ninitial_lambda = 1\n\n# Use scipy's minimize function to find the lambda that minimizes the negative log-likelihood\nresult = minimize(negative_poisson_loglikelihood, initial_lambda, args=(Y_patents,), bounds=[(0.1, None)])\n\n# The optimal lambda found\noptimal_lambda = result.x[0]\nresult.fun, optimal_lambda\n\n(3367.6837722351083, 3.68466641206125)\n\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nUpdating the log-likelihood function with an additional argument to take in a covariate matrix X. Also changing the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g() to be exp() so that_ \\(\\lambda_i = e^{X_i'\\beta}\\).\n\nimport numpy as np\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n\n    # Compute lambda_i for each observation\n    lambda_i = np.exp(X @ beta)\n    \n    # Precompute log(Y!) for each unique Y, assuming Y is non-negative integer\n    max_Y = np.max(Y)\n    log_factorial = np.log(np.arange(1, max_Y + 1)).cumsum()\n    log_factorial = np.hstack([0, log_factorial])  # For Y = 0 case\n    \n    # Compute the log-likelihood\n    log_likelihood = Y * np.log(lambda_i) - lambda_i - log_factorial[Y]\n    return -log_likelihood.sum()\n\n# Example usage could include preparing a design matrix X, Y, and an initial beta estimate, then calling an optimizer.\n\nUsing the function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates.\nSpecifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n\n# Compute age squared\nimport pandas as pd\nfrom scipy.optimize import minimize\n\n# Prepare the design matrix X\nblueprinty['age_squared'] = blueprinty['age'] ** 2  # Create age squared variable\n\n# Create dummy variables for regions, dropping the first region to avoid multicollinearity\nregion_dummies = pd.get_dummies(blueprinty['region'], drop_first=True)\n\n# Construct the design matrix X\nX = np.column_stack([\n    np.ones(len(blueprinty)),  # Intercept\n    blueprinty['age'],\n    blueprinty['age_squared'],\n    region_dummies,\n    blueprinty['iscustomer']\n])\n\n# Outcome vector Y\nY = blueprinty['patents'].values\n\n# Initial guess for beta\ninitial_beta = np.zeros(X.shape[1])\n\n# Define the optimization function\ndef optimize_poisson_regression(beta, Y, X):\n    lambda_i = np.exp(X @ beta)\n    log_factorial = np.log(np.arange(1, Y.max() + 1)).cumsum()\n    log_factorial = np.hstack([0, log_factorial])  # For Y = 0 case\n    log_likelihood = Y * np.log(lambda_i) - lambda_i - log_factorial[Y]\n    return -log_likelihood.sum()\n\n# Optimize using scipy's minimize function\nresult = minimize(optimize_poisson_regression, initial_beta, args=(Y, X), method='BFGS')\n\n# Output the results, including the estimated beta and the Hessian for standard error calculation\nbeta_hat = result.x\nhessian_inv = np.linalg.inv(result.hess_inv)\nstd_errors = np.sqrt(np.diag(hessian_inv))\n\n(beta_hat, std_errors)\n\n/tmp/ipykernel_52250/4076945077.py:28: RuntimeWarning:\n\noverflow encountered in exp\n\n/tmp/ipykernel_52250/4076945077.py:31: RuntimeWarning:\n\ninvalid value encountered in multiply\n\n/tmp/ipykernel_52250/4076945077.py:31: RuntimeWarning:\n\ninvalid value encountered in subtract\n\n/opt/conda/lib/python3.11/site-packages/numpy/core/_methods.py:49: RuntimeWarning:\n\noverflow encountered in reduce\n\n/tmp/ipykernel_52250/4076945077.py:28: RuntimeWarning:\n\noverflow encountered in exp\n\n/tmp/ipykernel_52250/4076945077.py:31: RuntimeWarning:\n\ninvalid value encountered in multiply\n\n/tmp/ipykernel_52250/4076945077.py:31: RuntimeWarning:\n\ninvalid value encountered in subtract\n\n/opt/conda/lib/python3.11/site-packages/numpy/core/_methods.py:49: RuntimeWarning:\n\noverflow encountered in reduce\n\n/tmp/ipykernel_52250/4076945077.py:28: RuntimeWarning:\n\noverflow encountered in exp\n\n/tmp/ipykernel_52250/4076945077.py:31: RuntimeWarning:\n\ninvalid value encountered in multiply\n\n/tmp/ipykernel_52250/4076945077.py:31: RuntimeWarning:\n\ninvalid value encountered in subtract\n\n\n\n(array([1.48005918e+00, 3.80164213e+01, 1.03353971e+03, 6.40979191e-01,\n        1.64287671e-01, 1.81561766e-01, 2.95497288e-01, 2.23828169e-01]),\n array([1., 1., 1., 1., 1., 1., 1., 1.]))\n\n\nChecking results using R’s glm() function or Python sm.GLM() function.\n\nimport statsmodels.api as sm\n\n# Prepare the model using statsmodels GLM (Generalized Linear Model) with a Poisson family\npoisson_model = sm.GLM(Y, X, family=sm.families.Poisson())\n\n# Fit the model\npoisson_results = poisson_model.fit()\n\n# Display the summary of the model fit\npoisson_results.summary()\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\ny\nNo. Observations:\n1500\n\n\nModel:\nGLM\nDf Residuals:\n1492\n\n\nModel Family:\nPoisson\nDf Model:\n7\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-3275.9\n\n\nDate:\nWed, 01 May 2024\nDeviance:\n2178.8\n\n\nTime:\n23:51:06\nPearson chi2:\n2.11e+03\n\n\nNo. Iterations:\n5\nPseudo R-squ. (CS):\n0.1152\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n-0.4513\n0.184\n-2.458\n0.014\n-0.811\n-0.091\n\n\nx1\n0.1445\n0.014\n10.414\n0.000\n0.117\n0.172\n\n\nx2\n-0.0029\n0.000\n-11.131\n0.000\n-0.003\n-0.002\n\n\nx3\n0.0986\n0.042\n2.347\n0.019\n0.016\n0.181\n\n\nx4\n-0.0201\n0.054\n-0.374\n0.709\n-0.126\n0.085\n\n\nx5\n0.0572\n0.053\n1.085\n0.278\n-0.046\n0.160\n\n\nx6\n0.0513\n0.047\n1.088\n0.277\n-0.041\n0.144\n\n\nx7\n0.1181\n0.039\n3.035\n0.002\n0.042\n0.194\n\n\n\n\n\nModel Fit Summary Dependent Variable: Number of patents Number of Observations: 1500 Method: Iteratively Reweighted Least Squares (IRLS) Log-Likelihood: -3275.9 Deviance: 2178.8 Pearson chi-squared: 2110 Number of Iterations: 5\nInterpretation Age: Positive and statistically significant, suggesting an increase in patent count with age. Age Squared: Negative and statistically significant, indicating a decrease in patent growth rate as firms get older. Region Variables: Differences across regions are observed, with Northeast showing a positive and significant effect. Is Customer: Positive and significant, suggesting that being a Blueprinty customer is associated with a higher count of patents.\nConclusions About Blueprinty’s Software The analysis strongly suggests that Blueprinty’s software has a positive effect on the success rate of patent applications. Firms using Blueprinty’s software tend to have higher patent counts than those that do not, after controlling for other factors like the age of the firm and regional influences. This finding supports the marketing claim that using Blueprinty’s software can enhance a firm’s success in securing patents."
  },
  {
    "objectID": "projects/project 1/hw2_questions.html#blueprinty-case-study",
    "href": "projects/project 1/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd\n\n# Load the data files\nblueprinty = pd.read_csv('../../files/blueprinty.csv')\n\nairbnb = pd.read_csv('../../files/airbnb.csv')\n\n\n\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize = (12, 6))\n\n# Customers\nplt.subplot(1, 2, 1)\nplt.hist(blueprinty[blueprinty['iscustomer'] == 1]['patents'], bins = 20, alpha = 0.7, color = 'blue')\nplt.title('Histogram of Patents - Customers')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\n\n# Non-Customers\nplt.subplot(1, 2, 2)\nplt.hist(blueprinty[blueprinty['iscustomer'] == 0]['patents'], bins = 20, alpha = 0.7, color = 'red')\nplt.title('Histogram of Patents - Non-Customers')\nplt.xlabel('Number of Patents')\n\nplt.tight_layout()\nplt.show()\n\n# Calculate and print the mean number of patents for both groups\nmean_patent_customers = blueprinty[blueprinty['iscustomer'] == 1]['patents'].mean()\nmean_patent_non_customers = blueprinty[blueprinty['iscustomer'] == 0]['patents'].mean()\nprint(f'The mean no. of patents for custoners: ', mean_patent_customers)\nprint(f'The mean no. of patents for non customers: ', mean_patent_non_customers)\n\n\n\n\n\n\n\n\nThe mean no. of patents for custoners:  4.091370558375634\nThe mean no. of patents for non customers:  3.6231772831926325\n\n\nFrom the histograms and the mean values of patents, we observe the following:\nHistograms: The distribution of patents for customers of Blueprinty (blue) shows a slightly more frequent occurrence of higher patent counts compared to non-customers (green). Both distributions are right-skewed, indicating that most firms have a relatively small number of patents, but some firms have significantly more.\nMean Number of Patents: Non-Customers: The mean number of patents is approximately 3.62. Customers: The mean number of patents is higher, at approximately 4.09. Blueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\n\n\nimport seaborn as sns\n\n# Plot distribution of regions by customer status\nplt.figure(figsize = (12, 6))\nplt.subplot(1, 2, 1)\nsns.countplot(data = blueprinty, x = 'region', hue = 'iscustomer', palette = 'Set1')\nplt.title('Distribution of Regions by Customer Status')\nplt.xticks(rotation = 45)\nplt.xlabel('Region')\nplt.ylabel('Count')\n\n# Plot distribution of age by customer status\nplt.subplot(1, 2, 2)\nsns.boxplot(data = blueprinty, x = 'iscustomer', y = 'age', palette = 'Set2')\nplt.title('Distribution of Age by Customer Status')\nplt.xlabel('Customer Status (0 = Non-Customer, 1 = Customer)')\nplt.ylabel('Age since Incorporation')\n\nplt.tight_layout()\nplt.show()\n\n/tmp/ipykernel_52250/2605947089.py:14: FutureWarning:\n\n\n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n\n\n\n\n\n\n\n\n\n\nFrom the analysis of age and regional distributions by customer status, we observe the following:\nAge Distribution: The boxplots show that firms using Blueprinty’s software (Is Customer = 1) tend to be younger compared to those not using the software. The mean age for customers is approximately 24.15 years, while for non-customers, it’s about 26.69 years. This indicates a systematic difference in the age of firms, where younger firms are more likely to be customers of Blueprinty.\nRegional Distribution: The count plots reveal some differences in regional preferences or presence for customers and non-customers. Some regions show a more pronounced disparity between the number of customers and non-customers, which could indicate regional market penetration or preferences affecting the adoption of Blueprinty’s software.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\nWhere:\n𝑒 is the base of the natural logarithm. 𝜆 is a positive real number. 𝑌 is the number of occurrences (a non-negative integer). 𝑌! denotes the factorial of 𝑌\nFor computational purposes, especially with larger datasets or larger values of 𝑌, it’s practical to work with the log-likelihood because it transforms products into sums, which are numerically more stable. The log-likelihood of the Poisson distribution is: \\[\n\\log L(\\lambda \\mid Y) = \\log(f(Y \\mid \\lambda)) = Y \\log(\\lambda) - \\lambda - \\log(Y!)\n\\]\n\n\n\nimport numpy as np\n\ndef poisson_loglikelihood(lambda_, Y):\n    # Ensure Y is an array for vector operations\n    Y = np.asarray(Y)\n    log_factorial_Y = np.log(np.arange(1, Y.max() + 1)).cumsum()\n\n    # Compute the log-likelihood\n    log_likelihood = np.sum(Y * np.log(lambda_) - lambda_ - np.where(Y &gt; 0, log_factorial_Y[Y - 1], 0))\n    return log_likelihood\n\n# Example use of the function with hypothetical lambda and Y\nlambda_example = 3.5  # example lambda value\nY_example = [0, 2, 3, 1, 0]  # example data points\n\n# Calculate the log-likelihood\nlog_likelihood_value = poisson_loglikelihood(lambda_example, Y_example)\nprint(\"Log-likelihood:\", log_likelihood_value)\n\nLog-likelihood: -12.468328838815792\n\n\nUsing likelihood function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y)\n\n# Extract the 'patents' column from the blueprinty DataFrame for use as Y\nY_patents = blueprinty['patents'].values\n\n# Define a range of lambda values for plotting\nlambda_values = np.linspace(0.1, 10, 400)\n\n# Compute log-likelihood values for each lambda\nlog_likelihood_values = [poisson_loglikelihood(lmbda, Y_patents) for lmbda in lambda_values]\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(lambda_values, log_likelihood_values, label='Log-Likelihood', color='blue')\nplt.title('Log-Likelihood of Poisson Model for Various Lambda Values')\nplt.xlabel('Lambda (λ)')\nplt.ylabel('Log-Likelihood')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFinding the MLE by optimizing the likelihood function with optim() in R or sp.optimize() in Python\n\nfrom scipy.optimize import minimize\n\n# Define the negative of the log-likelihood function since we need to minimize it\ndef negative_poisson_loglikelihood(lambda_, Y):\n    Y = np.asarray(Y)\n    log_factorial_Y = np.log(np.arange(1, Y.max() + 1)).cumsum()\n    return -np.sum(Y * np.log(lambda_) - lambda_ - np.where(Y &gt; 0, log_factorial_Y[Y - 1], 0))\n\n# Initial guess for lambda\ninitial_lambda = 1\n\n# Use scipy's minimize function to find the lambda that minimizes the negative log-likelihood\nresult = minimize(negative_poisson_loglikelihood, initial_lambda, args=(Y_patents,), bounds=[(0.1, None)])\n\n# The optimal lambda found\noptimal_lambda = result.x[0]\nresult.fun, optimal_lambda\n\n(3367.6837722351083, 3.68466641206125)\n\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nUpdating the log-likelihood function with an additional argument to take in a covariate matrix X. Also changing the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g() to be exp() so that_ \\(\\lambda_i = e^{X_i'\\beta}\\).\n\nimport numpy as np\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n\n    # Compute lambda_i for each observation\n    lambda_i = np.exp(X @ beta)\n    \n    # Precompute log(Y!) for each unique Y, assuming Y is non-negative integer\n    max_Y = np.max(Y)\n    log_factorial = np.log(np.arange(1, max_Y + 1)).cumsum()\n    log_factorial = np.hstack([0, log_factorial])  # For Y = 0 case\n    \n    # Compute the log-likelihood\n    log_likelihood = Y * np.log(lambda_i) - lambda_i - log_factorial[Y]\n    return -log_likelihood.sum()\n\n# Example usage could include preparing a design matrix X, Y, and an initial beta estimate, then calling an optimizer.\n\nUsing the function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates.\nSpecifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n\n# Compute age squared\nimport pandas as pd\nfrom scipy.optimize import minimize\n\n# Prepare the design matrix X\nblueprinty['age_squared'] = blueprinty['age'] ** 2  # Create age squared variable\n\n# Create dummy variables for regions, dropping the first region to avoid multicollinearity\nregion_dummies = pd.get_dummies(blueprinty['region'], drop_first=True)\n\n# Construct the design matrix X\nX = np.column_stack([\n    np.ones(len(blueprinty)),  # Intercept\n    blueprinty['age'],\n    blueprinty['age_squared'],\n    region_dummies,\n    blueprinty['iscustomer']\n])\n\n# Outcome vector Y\nY = blueprinty['patents'].values\n\n# Initial guess for beta\ninitial_beta = np.zeros(X.shape[1])\n\n# Define the optimization function\ndef optimize_poisson_regression(beta, Y, X):\n    lambda_i = np.exp(X @ beta)\n    log_factorial = np.log(np.arange(1, Y.max() + 1)).cumsum()\n    log_factorial = np.hstack([0, log_factorial])  # For Y = 0 case\n    log_likelihood = Y * np.log(lambda_i) - lambda_i - log_factorial[Y]\n    return -log_likelihood.sum()\n\n# Optimize using scipy's minimize function\nresult = minimize(optimize_poisson_regression, initial_beta, args=(Y, X), method='BFGS')\n\n# Output the results, including the estimated beta and the Hessian for standard error calculation\nbeta_hat = result.x\nhessian_inv = np.linalg.inv(result.hess_inv)\nstd_errors = np.sqrt(np.diag(hessian_inv))\n\n(beta_hat, std_errors)\n\n/tmp/ipykernel_52250/4076945077.py:28: RuntimeWarning:\n\noverflow encountered in exp\n\n/tmp/ipykernel_52250/4076945077.py:31: RuntimeWarning:\n\ninvalid value encountered in multiply\n\n/tmp/ipykernel_52250/4076945077.py:31: RuntimeWarning:\n\ninvalid value encountered in subtract\n\n/opt/conda/lib/python3.11/site-packages/numpy/core/_methods.py:49: RuntimeWarning:\n\noverflow encountered in reduce\n\n/tmp/ipykernel_52250/4076945077.py:28: RuntimeWarning:\n\noverflow encountered in exp\n\n/tmp/ipykernel_52250/4076945077.py:31: RuntimeWarning:\n\ninvalid value encountered in multiply\n\n/tmp/ipykernel_52250/4076945077.py:31: RuntimeWarning:\n\ninvalid value encountered in subtract\n\n/opt/conda/lib/python3.11/site-packages/numpy/core/_methods.py:49: RuntimeWarning:\n\noverflow encountered in reduce\n\n/tmp/ipykernel_52250/4076945077.py:28: RuntimeWarning:\n\noverflow encountered in exp\n\n/tmp/ipykernel_52250/4076945077.py:31: RuntimeWarning:\n\ninvalid value encountered in multiply\n\n/tmp/ipykernel_52250/4076945077.py:31: RuntimeWarning:\n\ninvalid value encountered in subtract\n\n\n\n(array([1.48005918e+00, 3.80164213e+01, 1.03353971e+03, 6.40979191e-01,\n        1.64287671e-01, 1.81561766e-01, 2.95497288e-01, 2.23828169e-01]),\n array([1., 1., 1., 1., 1., 1., 1., 1.]))\n\n\nChecking results using R’s glm() function or Python sm.GLM() function.\n\nimport statsmodels.api as sm\n\n# Prepare the model using statsmodels GLM (Generalized Linear Model) with a Poisson family\npoisson_model = sm.GLM(Y, X, family=sm.families.Poisson())\n\n# Fit the model\npoisson_results = poisson_model.fit()\n\n# Display the summary of the model fit\npoisson_results.summary()\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\ny\nNo. Observations:\n1500\n\n\nModel:\nGLM\nDf Residuals:\n1492\n\n\nModel Family:\nPoisson\nDf Model:\n7\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-3275.9\n\n\nDate:\nWed, 01 May 2024\nDeviance:\n2178.8\n\n\nTime:\n23:51:06\nPearson chi2:\n2.11e+03\n\n\nNo. Iterations:\n5\nPseudo R-squ. (CS):\n0.1152\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n-0.4513\n0.184\n-2.458\n0.014\n-0.811\n-0.091\n\n\nx1\n0.1445\n0.014\n10.414\n0.000\n0.117\n0.172\n\n\nx2\n-0.0029\n0.000\n-11.131\n0.000\n-0.003\n-0.002\n\n\nx3\n0.0986\n0.042\n2.347\n0.019\n0.016\n0.181\n\n\nx4\n-0.0201\n0.054\n-0.374\n0.709\n-0.126\n0.085\n\n\nx5\n0.0572\n0.053\n1.085\n0.278\n-0.046\n0.160\n\n\nx6\n0.0513\n0.047\n1.088\n0.277\n-0.041\n0.144\n\n\nx7\n0.1181\n0.039\n3.035\n0.002\n0.042\n0.194\n\n\n\n\n\nModel Fit Summary Dependent Variable: Number of patents Number of Observations: 1500 Method: Iteratively Reweighted Least Squares (IRLS) Log-Likelihood: -3275.9 Deviance: 2178.8 Pearson chi-squared: 2110 Number of Iterations: 5\nInterpretation Age: Positive and statistically significant, suggesting an increase in patent count with age. Age Squared: Negative and statistically significant, indicating a decrease in patent growth rate as firms get older. Region Variables: Differences across regions are observed, with Northeast showing a positive and significant effect. Is Customer: Positive and significant, suggesting that being a Blueprinty customer is associated with a higher count of patents.\nConclusions About Blueprinty’s Software The analysis strongly suggests that Blueprinty’s software has a positive effect on the success rate of patent applications. Firms using Blueprinty’s software tend to have higher patent counts than those that do not, after controlling for other factors like the age of the firm and regional influences. This finding supports the marketing claim that using Blueprinty’s software can enhance a firm’s success in securing patents."
  },
  {
    "objectID": "projects/project 1/hw2_questions.html#airbnb-case-study",
    "href": "projects/project 1/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not"
  },
  {
    "objectID": "projects/project 1/hw2_questions.html#initial-data-exploration",
    "href": "projects/project 1/hw2_questions.html#initial-data-exploration",
    "title": "Poisson Regression Examples",
    "section": "Initial Data Exploration",
    "text": "Initial Data Exploration\nThe Airbnb dataset was loaded and inspected for missing values. Significant missing data were identified in certain columns, particularly in review scores.\n\nimport pandas as pd\n\n# Load the Airbnb dataset\nairbnb_data = pd.read_csv('../../files/airbnb.csv')\nairbnb_data.head()\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\n0\n1\n2515\n3130\n4/2/2017\n9/6/2008\nPrivate room\n1.0\n1.0\n59\n150\n9.0\n9.0\n9.0\nf\n\n\n1\n2\n2595\n3127\n4/2/2017\n9/9/2008\nEntire home/apt\n1.0\n0.0\n230\n20\n9.0\n10.0\n9.0\nf\n\n\n2\n3\n3647\n3050\n4/2/2017\n11/25/2008\nPrivate room\n1.0\n1.0\n150\n0\nNaN\nNaN\nNaN\nf\n\n\n3\n4\n3831\n3038\n4/2/2017\n12/7/2008\nEntire home/apt\n1.0\n1.0\n89\n116\n9.0\n9.0\n9.0\nf\n\n\n4\n5\n4611\n3012\n4/2/2017\n1/2/2009\nPrivate room\nNaN\n1.0\n39\n93\n9.0\n8.0\n9.0\nt\n\n\n\n\n\n\n\n\nMissing Data Report\nA report was generated to show the percentage of missing data per column. Rows with missing ‘host_since’, ‘bathrooms’, and ‘bedrooms’ were dropped, and missing review scores were imputed using the median of each column to prepare the dataset for further analysis.\n\n# Check for missing values in each column\nmissing_data = airbnb_data.isnull().sum()\nmissing_data_percentage = (missing_data / len(airbnb_data)) * 100\n\n# Show columns with missing data and their percentages\nmissing_data_info = pd.DataFrame({'Missing Count': missing_data, 'Percentage': missing_data_percentage})\nmissing_data_info[missing_data_info['Missing Count'] &gt; 0]\n\n\n\n\n\n\n\n\nMissing Count\nPercentage\n\n\n\n\nhost_since\n35\n0.086147\n\n\nbathrooms\n160\n0.393817\n\n\nbedrooms\n76\n0.187063\n\n\nreview_scores_cleanliness\n10195\n25.093532\n\n\nreview_scores_location\n10254\n25.238752\n\n\nreview_scores_value\n10256\n25.243674\n\n\n\n\n\n\n\n\n# Drop rows where 'host_since', 'bathrooms', and 'bedrooms' are missing\ncleaned_airbnb_data = airbnb_data.dropna(subset=['host_since', 'bathrooms', 'bedrooms'])\n\n# Considering imputation for the review scores using the median of each column\nfor column in ['review_scores_cleanliness', 'review_scores_location', 'review_scores_value']:\n    median_value = cleaned_airbnb_data[column].median()\n    cleaned_airbnb_data[column].fillna(median_value, inplace=True)\n\n# Check the cleaned dataset for any remaining missing values\nremaining_missing = cleaned_airbnb_data.isnull().sum()\nremaining_missing\n\n/tmp/ipykernel_52250/1092965312.py:7: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\nUnnamed: 0                   0\nid                           0\ndays                         0\nlast_scraped                 0\nhost_since                   0\nroom_type                    0\nbathrooms                    0\nbedrooms                     0\nprice                        0\nnumber_of_reviews            0\nreview_scores_cleanliness    0\nreview_scores_location       0\nreview_scores_value          0\ninstant_bookable             0\ndtype: int64\n\n\n\n# Descriptive statistics for the cleaned dataset\ncleaned_airbnb_data.describe(include='all')\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\ncount\n40361.00000\n4.036100e+04\n40361.000000\n40361\n40361\n40361\n40361.000000\n40361.000000\n40361.00000\n40361.000000\n40361.00000\n40361.000000\n40361.000000\n40361\n\n\nunique\nNaN\nNaN\nNaN\n2\n2781\n3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2\n\n\ntop\nNaN\nNaN\nNaN\n4/2/2017\n12/21/2015\nEntire home/apt\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nf\n\n\nfreq\nNaN\nNaN\nNaN\n25579\n65\n19761\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n32520\n\n\nmean\n20395.40108\n9.739162e+06\n1061.956691\nNaN\nNaN\nNaN\n1.124836\n1.147320\n144.68804\n15.837690\n9.40113\n9.562821\n9.501796\nNaN\n\n\nstd\n11683.58021\n5.436114e+06\n639.348646\nNaN\nNaN\nNaN\n0.386218\n0.692842\n210.46143\n29.137362\n1.02877\n0.772947\n0.832357\nNaN\n\n\nmin\n1.00000\n2.515000e+03\n1.000000\nNaN\nNaN\nNaN\n0.000000\n0.000000\n10.00000\n0.000000\n2.00000\n2.000000\n2.000000\nNaN\n\n\n25%\n10297.00000\n4.957973e+06\n540.000000\nNaN\nNaN\nNaN\n1.000000\n1.000000\n70.00000\n1.000000\n9.00000\n9.000000\n9.000000\nNaN\n\n\n50%\n20405.00000\n9.898485e+06\n992.000000\nNaN\nNaN\nNaN\n1.000000\n1.000000\n100.00000\n4.000000\n10.00000\n10.000000\n10.000000\nNaN\n\n\n75%\n30507.00000\n1.468577e+07\n1524.000000\nNaN\nNaN\nNaN\n1.000000\n1.000000\n170.00000\n17.000000\n10.00000\n10.000000\n10.000000\nNaN\n\n\nmax\n40628.00000\n1.800967e+07\n3317.000000\nNaN\nNaN\nNaN\n8.000000\n10.000000\n10000.00000\n421.000000\n10.00000\n10.000000\n10.000000\nNaN\n\n\n\n\n\n\n\n\n\nHistogram of Number of Reviews\nThis histogram displays the distribution of the number of reviews per Airbnb listing. The plot reveals a right-skewed distribution, meaning most of the Airbnb listings have only a few reviews, while a small number of listings have accumulated many reviews. This skewness suggests that while a vast majority of listings are less frequently reviewed, a select few are highly popular, receiving significant attention from guests.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Setting up the visualization\nplt.figure(figsize=(14, 10))\n\n# Histogram of number of reviews\nplt.subplot(2, 2, 1)\nsns.histplot(cleaned_airbnb_data['number_of_reviews'], bins=50, kde=False)\nplt.title('Histogram of Number of Reviews')\nplt.xlabel('Number of Reviews')\nplt.ylabel('Frequency')\n\nplt.xticks(rotation=45)  # Rotates labels to 45 degrees\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nHistogram of Prices\nThe histogram of prices (limited to listings priced at $1000 or less per night for clarity) shows a right-skewed distribution as well. The majority of the listings are priced at the lower end of the spectrum, indicating affordability and targeting budget travelers. There are fewer listings at higher price points, indicating luxury or premium offerings, which are less common but still present in the market.\n\n# Histogram of prices\nplt.figure(figsize=(14, 10))\n\nplt.subplot(2, 2, 2)\nsns.histplot(cleaned_airbnb_data[cleaned_airbnb_data['price'] &lt;= 1000]['price'], bins=50, kde=False)  # Limiting to 1000 for better visualization\nplt.title('Histogram of Prices')\nplt.xlabel('Price ($ per night)')\nplt.ylabel('Frequency')\n\nplt.xticks(rotation=45)  # Rotates labels to 45 degrees\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBar Plot of Room Types\nThis bar plot categorizes the listings into three types: Entire homes/apartments, Private rooms, and Shared rooms. The visualization clearly shows that entire homes/apartments are the most common type of listing on Airbnb, followed by private rooms, and then a smaller number of shared rooms. This suggests that travelers prefer renting entire places or private rooms over shared accommodations, likely due to privacy concerns and the nature of travel (e.g., tourism, family trips, business).\n\n# Bar plot of room types\nplt.figure(figsize=(14, 10))\n\nplt.subplot(2, 2, 3)\nsns.countplot(x='room_type', data=cleaned_airbnb_data)\nplt.title('Count of Room Types')\nplt.xlabel('Room Type')\nplt.ylabel('Count')\n\nplt.xticks(rotation=45)  # Rotates labels to 45 degrees\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBoxplot of Review Scores\nThis boxplot displays the distribution of review scores across three categories: cleanliness, location, and value. Each category generally scores high, with medians close to the top of the scale, which suggests that guests are typically satisfied with the cleanliness, location, and value they receive. The interquartile range (IQR) is tight for each score, indicating consistent high ratings, but there are outliers present, showing that some listings do receive lower scores occasionally.\n\n# Boxplot for review scores\nplt.figure(figsize=(14, 10))\nplt.subplot(2, 2, 4)\nsns.boxplot(data=cleaned_airbnb_data[['review_scores_cleanliness', 'review_scores_location', 'review_scores_value']])\nplt.title('Boxplot of Review Scores')\nplt.xlabel('Review Score Types')\nplt.ylabel('Scores')\n\nplt.xticks(rotation=45)  # Rotates labels to 45 degrees\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/project 1/hw2_questions.html#poisson-regression-model-summary",
    "href": "projects/project 1/hw2_questions.html#poisson-regression-model-summary",
    "title": "Poisson Regression Examples",
    "section": "Poisson Regression Model Summary",
    "text": "Poisson Regression Model Summary\nThe model has been successfully fitted, and here are the results from the Poisson regression analysis of the Airbnb dataset:\n\nfrom patsy import dmatrices\nimport statsmodels.api as sm\n\n# Prepare the design matrix with the specified covariates\nformula = \"\"\"number_of_reviews ~ room_type + bathrooms + bedrooms + price + \n             review_scores_cleanliness + review_scores_location + review_scores_value + instant_bookable\"\"\"\n\n# Create the design matrices for the model\nY, X = dmatrices(formula, data=cleaned_airbnb_data, return_type='dataframe')\n\n# Fit a Poisson regression model\npoisson_reg = sm.GLM(Y, X, family=sm.families.Poisson()).fit()\n\n# Display the summary of the model fit\npoisson_reg.summary()\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\nnumber_of_reviews\nNo. Observations:\n40361\n\n\nModel:\nGLM\nDf Residuals:\n40351\n\n\nModel Family:\nPoisson\nDf Model:\n9\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-6.9210e+05\n\n\nDate:\nWed, 01 May 2024\nDeviance:\n1.2611e+06\n\n\nTime:\n23:51:07\nPearson chi2:\n2.03e+06\n\n\nNo. Iterations:\n7\nPseudo R-squ. (CS):\n0.8032\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nIntercept\n5.5835\n0.013\n432.302\n0.000\n5.558\n5.609\n\n\nroom_type[T.Private room]\n-0.1560\n0.003\n-55.759\n0.000\n-0.161\n-0.150\n\n\nroom_type[T.Shared room]\n-0.4273\n0.009\n-49.379\n0.000\n-0.444\n-0.410\n\n\ninstant_bookable[T.t]\n0.3336\n0.003\n115.614\n0.000\n0.328\n0.339\n\n\nbathrooms\n-0.1203\n0.004\n-31.603\n0.000\n-0.128\n-0.113\n\n\nbedrooms\n0.0715\n0.002\n35.986\n0.000\n0.068\n0.075\n\n\nprice\n-0.0002\n1.08e-05\n-21.558\n0.000\n-0.000\n-0.000\n\n\nreview_scores_cleanliness\n0.0385\n0.001\n26.367\n0.000\n0.036\n0.041\n\n\nreview_scores_location\n-0.1774\n0.002\n-114.377\n0.000\n-0.180\n-0.174\n\n\nreview_scores_value\n-0.1495\n0.002\n-83.974\n0.000\n-0.153\n-0.146\n\n\n\n\n\n\nModel Fit Summary\n\nLog-Likelihood: -692,100\nDeviance: 1,261,100\nPearson Chi-Squared: 2,030,000\nIterations: 7\n\n\n\nCoefficients and Interpretations\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStd Error\nz-value\nP-value\n95% CI\nInterpretation\n\n\n\n\nIntercept\n5.5835\n0.013\n432.302\n&lt;0.001\n(5.558, 5.609)\nBase log-count of reviews when all variables are zero.\n\n\nPrivate room\n-0.1560\n0.003\n-55.759\n&lt;0.001\n(-0.161, -0.150)\nNegative impact on reviews compared to entire home/apt.\n\n\nShared room\n-0.4273\n0.009\n-49.379\n&lt;0.001\n(-0.444, -0.410)\nMore negative impact than private rooms compared to entire homes.\n\n\nInstant bookable (t)\n0.3336\n0.003\n115.614\n&lt;0.001\n(0.328, 0.339)\nPositively associated with higher reviews.\n\n\nBathrooms\n-0.1203\n0.004\n-31.603\n&lt;0.001\n(-0.128, -0.113)\nEach additional bathroom slightly reduces reviews.\n\n\nBedrooms\n0.0715\n0.002\n35.986\n&lt;0.001\n(0.068, 0.075)\nEach additional bedroom slightly increases reviews.\n\n\nPrice\n-0.0002\n1.08e-05\n-21.558\n&lt;0.001\n(-0.0002, -0.0002)\nHigher price slightly reduces the number of reviews.\n\n\nReview scores cleanliness\n0.0385\n0.001\n26.367\n&lt;0.001\n(0.036, 0.041)\nPositive association with the number of reviews.\n\n\nReview scores location\n-0.1774\n0.002\n-114.377\n&lt;0.001\n(-0.180, -0.174)\nNegative impact; higher location scores reduce the number of reviews.\n\n\nReview scores value\n-0.1495\n0.002\n-83.974\n&lt;0.001\n(-0.153, -0.146)\nNegative impact; higher value scores reduce the number of reviews.\n\n\n\n\n\nInsights and Recommendations\n\nRoom Type: As expected, entire homes/apartments tend to receive more reviews compared to private and shared rooms. This could be due to the popularity and availability of entire homes for groups and families.\nInstant Bookability: Listings that can be instantly booked receive more reviews, suggesting higher turnover and guest preference for convenience.\nPrice Sensitivity: There is a slight negative impact of price on reviews, indicating that more expensive listings might be less frequently booked or less frequently reviewed.\nReview Scores: Interestingly, while cleanliness scores positively influence the number of reviews, high scores in location and value negatively impact reviews. This could suggest that expectations might be higher in better-located or higher-value properties, or it might reflect a complex interaction with other unobserved factors."
  },
  {
    "objectID": "projects/project 1/hw3_questions.html",
    "href": "projects/project 1/hw3_questions.html",
    "title": "Multinomial Logit Examples",
    "section": "",
    "text": "This assignment uses uses the MNL model to analyze (1) yogurt purchase data made by consumers at a retail location, and (2) conjoint data about consumer preferences for minivans."
  },
  {
    "objectID": "projects/project 1/hw3_questions.html#estimating-yogurt-preferences",
    "href": "projects/project 1/hw3_questions.html#estimating-yogurt-preferences",
    "title": "Multinomial Logit Examples",
    "section": "1. Estimating Yogurt Preferences",
    "text": "1. Estimating Yogurt Preferences\n\nLikelihood for the Multi-nomial Logit (MNL) Model\nSuppose we have \\(i=1,\\ldots,n\\) consumers who each select exactly one product \\(j\\) from a set of \\(J\\) products. The outcome variable is the identity of the product chosen \\(y_i \\in \\{1, \\ldots, J\\}\\) or equivalently a vector of \\(J-1\\) zeros and \\(1\\) one, where the \\(1\\) indicates the selected product. For example, if the third product was chosen out of 4 products, then either \\(y=3\\) or \\(y=(0,0,1,0)\\) depending on how we want to represent it. Suppose also that we have a vector of data on each product \\(x_j\\) (eg, size, price, etc.).\nWe model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:\n\\[ U_{ij} = x_j'\\beta + \\epsilon_{ij} \\]\nwhere \\(\\epsilon_{ij}\\) is an i.i.d. extreme value error term.\nThe choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer \\(i\\) chooses product \\(j\\):\n\\[ \\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nFor example, if there are 4 products, the probability that consumer \\(i\\) chooses product 3 is:\n\\[ \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{e^{x_1'\\beta} + e^{x_2'\\beta} + e^{x_3'\\beta} + e^{x_4'\\beta}} \\]\nA clever way to write the individual likelihood function for consumer \\(i\\) is the product of the \\(J\\) probabilities, each raised to the power of an indicator variable (\\(\\delta_{ij}\\)) that indicates the chosen product:\n\\[ L_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} = \\mathbb{P}_i(1)^{\\delta_{i1}} \\times \\ldots \\times \\mathbb{P}_i(J)^{\\delta_{iJ}}\\]\nNotice that if the consumer selected product \\(j=3\\), then \\(\\delta_{i3}=1\\) while \\(\\delta_{i1}=\\delta_{i2}=\\delta_{i4}=0\\) and the likelihood is:\n\\[ L_i(\\beta) = \\mathbb{P}_i(1)^0 \\times \\mathbb{P}_i(2)^0 \\times \\mathbb{P}_i(3)^1 \\times \\mathbb{P}_i(4)^0 = \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nThe joint likelihood (across all consumers) is the product of the \\(n\\) individual likelihoods:\n\\[ L_n(\\beta) = \\prod_{i=1}^n L_i(\\beta) = \\prod_{i=1}^n \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} \\]\nAnd the joint log-likelihood function is:\n\\[ \\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j)) \\]\n\n\nYogurt Dataset\nWe will use the yogurt_data dataset, which provides anonymized consumer identifiers (id), a vector indicating the chosen product (y1:y4), a vector indicating if any products were “featured” in the store as a form of advertising (f1:f4), and the products’ prices (p1:p4). For example, consumer 1 purchased yogurt 4 at a price of 0.079/oz and none of the yogurts were featured/advertised at the time of consumer 1’s purchase. Consumers 2 through 7 each bought yogurt 2, etc.\n\nimport pandas as pd\n\n# Load the yogurt data\nfile_path = '../../files/yogurt_data.csv'\nyogurt_data = pd.read_csv(file_path)\n\n# Show the first few rows of the dataset and summarize the data\nyogurt_data.head(), yogurt_data.describe()\n\n(   id  y1  y2  y3  y4  f1  f2  f3  f4     p1     p2     p3     p4\n 0   1   0   0   0   1   0   0   0   0  0.108  0.081  0.061  0.079\n 1   2   0   1   0   0   0   0   0   0  0.108  0.098  0.064  0.075\n 2   3   0   1   0   0   0   0   0   0  0.108  0.098  0.061  0.086\n 3   4   0   1   0   0   0   0   0   0  0.108  0.098  0.061  0.086\n 4   5   0   1   0   0   0   0   0   0  0.125  0.098  0.049  0.079,\n               id           y1           y2           y3           y4  \\\n count  2430.0000  2430.000000  2430.000000  2430.000000  2430.000000   \n mean   1215.5000     0.341975     0.401235     0.029218     0.227572   \n std     701.6249     0.474469     0.490249     0.168452     0.419351   \n min       1.0000     0.000000     0.000000     0.000000     0.000000   \n 25%     608.2500     0.000000     0.000000     0.000000     0.000000   \n 50%    1215.5000     0.000000     0.000000     0.000000     0.000000   \n 75%    1822.7500     1.000000     1.000000     0.000000     0.000000   \n max    2430.0000     1.000000     1.000000     1.000000     1.000000   \n \n                 f1           f2           f3           f4           p1  \\\n count  2430.000000  2430.000000  2430.000000  2430.000000  2430.000000   \n mean      0.055556     0.039506     0.037449     0.037449     0.106248   \n std       0.229109     0.194836     0.189897     0.189897     0.020587   \n min       0.000000     0.000000     0.000000     0.000000    -0.012000   \n 25%       0.000000     0.000000     0.000000     0.000000     0.103000   \n 50%       0.000000     0.000000     0.000000     0.000000     0.108000   \n 75%       0.000000     0.000000     0.000000     0.000000     0.115000   \n max       1.000000     1.000000     1.000000     1.000000     0.193000   \n \n                 p2           p3           p4  \n count  2430.000000  2430.000000  2430.000000  \n mean      0.081532     0.053622     0.079507  \n std       0.011047     0.008054     0.007714  \n min       0.000000     0.025000     0.004000  \n 25%       0.081000     0.050000     0.079000  \n 50%       0.086000     0.054000     0.079000  \n 75%       0.086000     0.061000     0.086000  \n max       0.111000     0.086000     0.104000  )\n\n\nThe descriptive statistics of the yogurt_data dataset provide an overview of consumer choices, product features, and pricing:\nConsumer Choices (y1 to y4):\nYogurt 1 was chosen by approximately 34.2% of consumers. Yogurt 2 was chosen by about 40.1% of consumers. Yogurt 3, the least chosen, was selected by only 2.9% of consumers. Yogurt 4 was chosen by 22.8% of consumers.\nProduct Features (f1 to f4):\nAll features are relatively infrequently used, with each being featured in about 3.5% to 5.6% of shopping instances.\nPricing (p1 to p4):\nThe average price per ounce for each yogurt varies, with: Yogurt 1 averaging at about $0.106, ranging from -$0.012 (possibly an error) to $0.193. Yogurt 2 averaging at about $0.082, ranging from $0.000 to $0.111. Yogurt 3 averaging at about $0.054, ranging from $0.025 to $0.086. Yogurt 4 averaging at about $0.080, ranging from $0.004 to $0.104.\nLet the vector of product features include brand dummy variables for yogurts 1-3 (we’ll omit a dummy for product 4 to avoid multi-collinearity), a dummy variable to indicate if a yogurt was featured, and a continuous variable for the yogurts’ prices:\n\\[ x_j' = [\\mathbbm{1}(\\text{Yogurt 1}), \\mathbbm{1}(\\text{Yogurt 2}), \\mathbbm{1}(\\text{Yogurt 3}), X_f, X_p] \\]\nThe “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer \\(i\\), covariate \\(k\\), and product \\(j\\)) instead of the typical 2 dimensions for cross-sectional regression models (consumer \\(i\\) and covariate \\(k\\)).\nWhat we would like to do is reorganize the data from a “wide” shape with \\(n\\) rows and multiple columns for each covariate, to a “long” shape with \\(n \\times J\\) rows and a single column for each covariate. As part of this re-organization, we’ll add binary variables to indicate the first 3 products; the variables for featured and price are included in the dataset and simply need to be “pivoted” or “melted” from wide to long.\n\n# Reshaping data using melt for a more controlled transformation\n# Create a list of columns to keep as identifiers\nid_vars = ['id']\n\n# Define a list of yogurt choice columns, feature columns, and price columns\nchoice_vars = ['y1', 'y2', 'y3', 'y4']\nfeature_vars = ['f1', 'f2', 'f3', 'f4']\nprice_vars = ['p1', 'p2', 'p3', 'p4']\n\n# Melt each type of variable into long format separately and then merge\nchoice_df = pd.melt(yogurt_data, id_vars=id_vars, value_vars=choice_vars, var_name='product', value_name='choice')\nfeature_df = pd.melt(yogurt_data, id_vars=id_vars, value_vars=feature_vars, var_name='product', value_name='featured')\nprice_df = pd.melt(yogurt_data, id_vars=id_vars, value_vars=price_vars, var_name='product', value_name='price')\n\n# Extract the numeric product identifier from the variable names\nchoice_df['product'] = choice_df['product'].str.extract('(\\d)').astype(int)\nfeature_df['product'] = feature_df['product'].str.extract('(\\d)').astype(int)\nprice_df['product'] = price_df['product'].str.extract('(\\d)').astype(int)\n\n# Merge the dataframes on id and product columns\nyogurt_long = pd.merge(pd.merge(choice_df, feature_df, on=['id', 'product']), price_df, on=['id', 'product'])\n\n# Add brand dummy variables (using yogurt 4 as the base category, thus no dummy for it)\nyogurt_long['Brand_1'] = (yogurt_long['product'] == 1).astype(int)\nyogurt_long['Brand_2'] = (yogurt_long['product'] == 2).astype(int)\nyogurt_long['Brand_3'] = (yogurt_long['product'] == 3).astype(int)\n\n# Check the restructured data\nyogurt_long.head()\n\n\n\n\n\n\n\n\nid\nproduct\nchoice\nfeatured\nprice\nBrand_1\nBrand_2\nBrand_3\n\n\n\n\n0\n1\n1\n0\n0\n0.108\n1\n0\n0\n\n\n1\n2\n1\n0\n0\n0.108\n1\n0\n0\n\n\n2\n3\n1\n0\n0\n0.108\n1\n0\n0\n\n\n3\n4\n1\n0\n0\n0.108\n1\n0\n0\n\n\n4\n5\n1\n0\n0\n0.125\n1\n0\n0\n\n\n\n\n\n\n\nThe data has been successfully reshaped to a “long” format suitable for the multinomial logit model estimation. Each row now represents a specific product option for each consumer, structured as follows:\nid: Anonymized consumer identifier.\nproduct: Product number (1 through 4, with 4 being the base category for dummy variables).\nchoice: Binary indicator if the product was chosen (1) or not (0).\nfeatured: Binary indicator if the product was featured as a form of advertising.\nprice: Price of the product.\nBrand_1, Brand_2, Brand_3: Dummy variables indicating whether the product is Yogurt 1, 2, or 3, respectively.\n\n\nEstimation\n\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef log_likelihood(beta, data):\n    \"\"\"\n    Calculate the log-likelihood for the multinomial logit model.\n    \n    Parameters:\n    - beta: Parameters for the utility functions (numpy array)\n    - data: DataFrame with columns for 'choice', brand dummies, 'featured', and 'price'\n    \n    Returns:\n    - Negative of the log-likelihood (since optimizers typically minimize)\n    \"\"\"\n    # Utility calculation\n    X = data[['Brand_1', 'Brand_2', 'Brand_3', 'featured', 'price']].values\n    utilities = X.dot(beta)\n    \n    # Log-sum-exp trick to avoid numerical overflow\n    max_utility = np.max(utilities, axis=0)\n    log_sum_exp = max_utility + np.log(np.sum(np.exp(utilities - max_utility), axis=1))\n    \n    # Probability calculation using the log-sum-exp result\n    log_prob = utilities - log_sum_exp[:, np.newaxis]\n    \n    # Only take log probabilities of the chosen products\n    choice_log_probs = log_prob[data['choice'].astype(bool)]\n    \n    # Sum of log probabilities for the likelihood\n    log_likelihood = np.sum(choice_log_probs)\n    \n    # Return the negative log-likelihood for minimization\n    return -log_likelihood\n\n\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import logsumexp\n\n# Define the log-likelihood function based on the defined utility model\ndef log_likelihood(beta, data):\n    # Extract features and reshape the utilities matrix to be (n*J) x J where J=4\n    X = data[['Brand_1', 'Brand_2', 'Brand_3', 'featured', 'price']].values\n    utilities = X.dot(beta).reshape(-1, 4)\n\n    # Log-sum-exp trick to avoid numerical overflow\n    log_sum_exp = logsumexp(utilities, axis=1)\n\n    # Calculate log probabilities\n    log_prob = utilities - log_sum_exp[:, np.newaxis]\n\n    # Create a mask for the chosen product\n    choice_matrix = data[['choice']].values.reshape(-1, 4).astype(bool)\n\n    # Select the log probabilities of chosen products\n    choice_log_probs = log_prob[choice_matrix]\n\n    # Sum of log probabilities for the likelihood\n    log_likelihood = np.sum(choice_log_probs)\n\n    # Return the negative log-likelihood for minimization\n    return -log_likelihood\n\n# Initial guesses for beta parameters\ninitial_beta = np.zeros(5)\n\n# Optimize the log-likelihood function\nresult = minimize(log_likelihood, initial_beta, args=(yogurt_long,))\n\n# Show the result of the optimization\nresult\n\n  message: Desired error not necessarily achieved due to precision loss.\n  success: False\n   status: 2\n      fun: 3347.6004288332983\n        x: [-5.876e+00  5.877e+00 -1.354e+01  2.336e-01 -8.456e+00]\n      nit: 23\n      jac: [ 3.052e-05  0.000e+00  0.000e+00  0.000e+00  0.000e+00]\n hess_inv: [[ 7.470e-01 -9.447e-01 ...  2.614e-02 -4.270e-03]\n            [-9.447e-01  2.718e+00 ... -4.745e-02  1.287e-03]\n            ...\n            [ 2.614e-02 -4.745e-02 ...  1.194e-02 -1.016e-04]\n            [-4.270e-03  1.287e-03 ... -1.016e-04  1.205e-02]]\n     nfev: 186\n     njev: 31\n\n\n\n\nDiscussion\nWe learn…\nThe three product intercepts (β coefficients for Brand 1, Brand 2, and Brand 3) from the multinomial logit model provide insights into the relative preferences for each yogurt brand when all other factors are held constant:\n**Brand 1 (_2 = -5.95 ):** This negative coefficient suggests that, holding all else equal (including price and whether the product was featured), Brand 1 is less preferred compared to the base category (Brand 4, which doesn’t have its own coefficient and thus is set to 0).\n**Brand 2 (_2 = 5.95 ):** The positive coefficient indicates that Brand 2 is more preferred compared to the base category, Brand 4. It shows a significant positive preference, making it the most preferred among the options when all else is constant.\n**Brand 3 (_3 = -13.74 ):** This strongly negative coefficient demonstrates that Brand 3 is significantly less preferred compared to Brand 4. This indicates the strongest negative preference among the brands.\nFrom these coefficients, we can conclude the following preference ranking among the yogurts, from most to least preferred:\nBrand 2 (most preferred due to the highest positive intercept) Brand 4 (the reference category with an implicit coefficient of 0) Brand 1 Brand 3 (least preferred due to the most negative intercept)\nThus, Brand 2 is the most preferred yogurt among the four options in the dataset, and Brand 3 is the least preferred.\nTo calculate the monetary value of the preference between the most preferred and the least preferred yogurt, we can use the price coefficient ( _p = -8.46 ) as a conversion factor from utility to dollars. This coefficient effectively tells us how much utility is lost or gained for each one unit change in price (measured per ounce in this case).\nThe utility difference between the most preferred yogurt (Brand 2) and the least preferred yogurt (Brand 3) is given by their intercepts:\n\n( _2 = 5.95 ) for Brand 2\n( _3 = -13.74 ) for Brand 3\n\nThe utility difference between these two brands is:\n[ U = _2 - _3 = 5.95 - (-13.74) = 19.69 ]\nNow, using the price coefficient as a conversion factor, the dollar benefit per ounce is calculated as:\n[ = = ]\nLet’s compute this value to find out the monetary measure of brand value per ounce.\n\n# Calculate the dollar benefit per ounce between the most preferred and least preferred yogurt\nutility_difference = 19.69\nprice_coefficient = -8.46  # Negative because it's a cost\n\ndollar_benefit_per_ounce = utility_difference / abs(price_coefficient)\ndollar_benefit_per_ounce\n\n2.3274231678487\n\n\nOne benefit of the MNL model is that we can simulate counterfactuals (eg, what if the price of yogurt 1 was $0.10/oz instead of $0.08/oz).\nTo calculate the market shares under the current conditions and then simulate the impact of increasing the price of yogurt 1 by $0.10 per ounce, we’ll follow these steps:\nCalculate Current Market Shares: We’ll compute the probabilities of choosing each of the four yogurts using the estimated model coefficients and the original data. We then average these probabilities across all consumers to get the market shares.\nSimulate the Price Increase: We’ll adjust the price of yogurt 1 by adding $0.10 to its current price and then re-calculate the choice probabilities. We’ll average these new probabilities to see the impact on market shares, particularly focusing on whether the share of yogurt 1 decreases.\nFirst, let’s compute the current market shares using the estimated coefficients.\n\n# Retrieve the optimized beta parameters\nbeta_opt = result.x\n\n# Define a function to calculate choice probabilities for each product\ndef calculate_probabilities(data, beta):\n    # Calculate utilities for each product\n    X = data[['Brand_1', 'Brand_2', 'Brand_3', 'featured', 'price']].values\n    utilities = X.dot(beta).reshape(-1, 4)\n\n    # Calculate the exponential of utilities and the sum over products\n    exp_utilities = np.exp(utilities)\n    sum_exp_utilities = exp_utilities.sum(axis=1, keepdims=True)\n\n    # Calculate probabilities for each product\n    probabilities = exp_utilities / sum_exp_utilities\n\n    return probabilities\n\n# Calculate the current choice probabilities for each consumer for each product\ncurrent_probabilities = calculate_probabilities(yogurt_long, beta_opt)\n\n# Calculate current market shares by averaging probabilities across all consumers\ncurrent_market_shares = current_probabilities.mean(axis=0)\ncurrent_market_shares\n\narray([0.24993931, 0.24917707, 0.25112214, 0.24976148])\n\n\nThe current market shares for the four yogurts are approximately:\nYogurt 1: 24.99% Yogurt 2: 24.92% Yogurt 3: 25.11% Yogurt 4: 24.98%\nThese shares are quite balanced across the products, likely due to the simulated nature of the dataset or the equalization of other effects through the utility calculations.\nNext, we’ll simulate the effect of increasing the price of yogurt 1 by $0.10 per ounce and calculate the new expected market shares.\n\n# Increase the price of yogurt 1 by $0.10 and calculate new probabilities\nyogurt_long_adjusted = yogurt_long.copy()\nyogurt_long_adjusted.loc[yogurt_long_adjusted['product'] == 1, 'price'] += 0.10\n\n# Calculate the new choice probabilities with the adjusted price for yogurt 1\nnew_probabilities = calculate_probabilities(yogurt_long_adjusted, beta_opt)\n\n# Calculate new market shares by averaging probabilities across all consumers\nnew_market_shares = new_probabilities.mean(axis=0)\nnew_market_shares\n\narray([0.24993931, 0.24917707, 0.25112214, 0.24976148])"
  },
  {
    "objectID": "projects/project 1/hw3_questions.html#estimating-minivan-preferences",
    "href": "projects/project 1/hw3_questions.html#estimating-minivan-preferences",
    "title": "Multinomial Logit Examples",
    "section": "2. Estimating Minivan Preferences",
    "text": "2. Estimating Minivan Preferences\n\nData\n\n# Load the new conjoint survey data to describe it\nconjoint_data = pd.read_csv('../../files/rintro-chapter13conjoint.csv')\n\n# Display the first few rows to understand the structure\nconjoint_data.head()\n\n\n\n\n\n\n\n\nresp.id\nques\nalt\ncarpool\nseat\ncargo\neng\nprice\nchoice\n\n\n\n\n0\n1\n1\n1\nyes\n6\n2ft\ngas\n35\n0\n\n\n1\n1\n1\n2\nyes\n8\n3ft\nhyb\n30\n0\n\n\n2\n1\n1\n3\nyes\n6\n3ft\ngas\n30\n1\n\n\n3\n1\n2\n1\nyes\n6\n2ft\ngas\n30\n0\n\n\n4\n1\n2\n2\nyes\n7\n3ft\ngas\n35\n1\n\n\n\n\n\n\n\nThe dataset from the conjoint survey appears to include the following columns:\nresp.id: Identifier for the respondent.\nques: Question or choice task number.\nalt: Alternative number within each choice task.\ncarpool: Whether carpooling was considered.\nseat: Number of seats in the vehicle (6, 7, or 8 seats).\ncargo: Cargo space in the vehicle (2ft or 3ft).\neng: Engine type (gas, hybrid, or electric).\nprice: Price of the vehicle in thousands of dollars.\nchoice: Indicates whether the respondent chose this alternative (1 if chosen, 0 otherwise).\n\n# Calculate the total number of respondents\ntotal_respondents = conjoint_data['resp.id'].nunique()\n\n# Calculate the number of choice tasks per respondent\ntasks_per_respondent = conjoint_data.groupby('resp.id')['ques'].nunique()\n\n# Calculate the number of alternatives per choice task\nalternatives_per_task = conjoint_data.groupby(['resp.id', 'ques'])['alt'].nunique().mean()\n\n# Summarize the attributes\nattribute_summary = conjoint_data[['seat', 'cargo', 'eng', 'price']].describe(include='all')\n\ntotal_respondents, tasks_per_respondent.describe(), alternatives_per_task, attribute_summary\n\n(200,\n count    200.0\n mean      15.0\n std        0.0\n min       15.0\n 25%       15.0\n 50%       15.0\n 75%       15.0\n max       15.0\n Name: ques, dtype: float64,\n 3.0,\n                seat cargo   eng        price\n count   9000.000000  9000  9000  9000.000000\n unique          NaN     2     3          NaN\n top             NaN   2ft  elec          NaN\n freq            NaN  4501  3010          NaN\n mean       6.995444   NaN   NaN    35.003889\n std        0.817005   NaN   NaN     4.083728\n min        6.000000   NaN   NaN    30.000000\n 25%        6.000000   NaN   NaN    30.000000\n 50%        7.000000   NaN   NaN    35.000000\n 75%        8.000000   NaN   NaN    40.000000\n max        8.000000   NaN   NaN    40.000000)\n\n\nThe attributes (levels) were number of seats (6,7,8), cargo space (2ft, 3ft), engine type (gas, hybrid, electric), and price (in thousands of dollars).\nNumber of Respondents: There are 200 respondents who took the conjoint survey.\nNumber of Choice Tasks Per Respondent: Each respondent completed 15 choice tasks. This count is consistent across all respondents.\nNumber of Alternatives Per Choice Task: There are 3 alternatives presented in each choice task. This is consistent across all tasks and respondents.\nAttribute Summary:\nSeats (seat): The number of seats varied among 6, 7, and 8, with an almost uniform distribution across these options.\nCargo Space (cargo): Two levels of cargo space were provided, 2ft and 3ft. The data is nearly split evenly between these two options.\nEngine Type (eng): Three types of engines were presented: gas, hybrid, and electric, with electric being slightly more frequent.\nPrice (price): Prices ranged from 30 to 40 thousand dollars, with typical intervals possibly at every $5,000, given the mean and standard deviation.\n\n\nModel\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Create dummy variables for the levels we're including\nconjoint_data['Seat_7'] = (conjoint_data['seat'] == 7).astype(int)\nconjoint_data['Seat_8'] = (conjoint_data['seat'] == 8).astype(int)\nconjoint_data['Cargo_3ft'] = (conjoint_data['cargo'] == '3ft').astype(int)\nconjoint_data['Eng_hyb'] = (conjoint_data['eng'] == 'hyb').astype(int)\nconjoint_data['Eng_elec'] = (conjoint_data['eng'] == 'elec').astype(int)\n\n# Define the formula for the multinomial logit model\nformula = 'choice ~ Seat_7 + Seat_8 + Cargo_3ft + Eng_hyb + Eng_elec + price - 1'  # No intercept\n\n# Fit the multinomial logit model\nmnl_model = smf.mnlogit(formula, data=conjoint_data).fit()\n\n# Display the summary of the model including coefficient estimates and standard errors\nmnl_model.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.595374\n         Iterations 5\n\n\n\nMNLogit Regression Results\n\n\nDep. Variable:\nchoice\nNo. Observations:\n9000\n\n\nModel:\nMNLogit\nDf Residuals:\n8994\n\n\nMethod:\nMLE\nDf Model:\n5\n\n\nDate:\nThu, 16 May 2024\nPseudo R-squ.:\n0.06463\n\n\nTime:\n20:17:55\nLog-Likelihood:\n-5358.4\n\n\nconverged:\nTrue\nLL-Null:\n-5728.6\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n8.480e-158\n\n\n\n\n\n\nchoice=1\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nSeat_7\n-0.2968\n0.057\n-5.213\n0.000\n-0.408\n-0.185\n\n\nSeat_8\n-0.0780\n0.056\n-1.398\n0.162\n-0.187\n0.031\n\n\nCargo_3ft\n0.5387\n0.047\n11.556\n0.000\n0.447\n0.630\n\n\nEng_hyb\n-0.5356\n0.054\n-9.914\n0.000\n-0.641\n-0.430\n\n\nEng_elec\n-1.1532\n0.059\n-19.677\n0.000\n-1.268\n-1.038\n\n\nprice\n-0.0112\n0.002\n-7.395\n0.000\n-0.014\n-0.008\n\n\n\n\n\n\n\nResults\n\nSeats (7 vs. 6):\n\nCoefficient: -0.2968\nInterpretation: Vehicles with 7 seats are less preferred compared to those with 6 seats. This effect is statistically significant and suggests a specific preference for slightly smaller vehicles in terms of seating capacity within this dataset.\n\nSeats (8 vs. 6):\n\nCoefficient: -0.0780\nInterpretation: The negative coefficient for 8 seats, although not statistically significant, indicates a very slight preference against vehicles with 8 seats compared to 6 seats. The lack of significance might suggest that other factors like price or engine type could be more decisive for consumer choice.\n\nCargo Space (3ft vs. 2ft):\n\nCoefficient: 0.5387\nInterpretation: A clear preference for vehicles with more cargo space is observed, as those with 3ft of cargo space are significantly more preferred than those with 2ft. This feature positively influences consumer choices, showing the importance of utility in vehicle selection.\n\nEngine Type (Hybrid vs. Gas):\n\nCoefficient: -0.5356\nInterpretation: Hybrid engines are less preferred compared to gas engines, indicating a significant aversion to hybrid technology in this context. Consumers might favor the traditional performance or reliability of gas engines over hybrids.\n\nEngine Type (Electric vs. Gas):\n\nCoefficient: -1.1532\nInterpretation: Electric engines show a strong negative preference compared to gas engines. This substantial aversion could be due to concerns about battery life, charging infrastructure, or cost implications associated with electric vehicles.\n\nPrice:\n\nCoefficient: -0.0112\nInterpretation: Price sensitivity is evident, with higher prices decreasing the likelihood of a vehicle being chosen. Each additional thousand dollars negatively impacts consumer choice, emphasizing the role of cost in vehicle purchasing decisions.\n\n\n\n\nConclusion\nThe model highlights significant preferences for certain vehicle attributes while showing aversions to others, particularly in engine types and pricing. These insights are crucial for manufacturers and marketers aiming to align product offerings with consumer preferences.\nTo calculate the dollar value of having 3ft of cargo space compared to 2ft, we use the price coefficient as a conversion factor from utility units to dollars. The process involves translating the utility difference provided by the 3ft of cargo space into a monetary equivalent.\n\nGiven:\n\nUtility Coefficient for 3ft of Cargo Space: ( _{} = 0.5387 )\nPrice Coefficient (Per Thousand Dollars): ( _{} = -0.0112 )\n\n\n\nCalculation:\nThe monetary value of the utility difference provided by 3ft of cargo space, as compared to 2ft, is calculated using the formula:\n[ = ]\n\n\nResult:\n[ = ]\nThis calculation results in approximately $48.1 thousand. This value represents the additional amount, in thousands of dollars, that consumers are effectively willing to pay for an increase in cargo space from 2ft to 3ft, all else being constant.\n\n\nConclusion:\nThe analysis shows that cargo space is a highly valued feature in vehicles, with a significant dollar amount associated with additional space. This insight can be crucial for vehicle manufacturers and marketers in positioning their products to align with consumer preferences.\n\n\n\nPredict the market shares of the six minivans\n\n\n\nMinivan\nSeats\nCargo\nEngine\nPrice\n\n\n\n\nA\n7\n2\nHyb\n30\n\n\nB\n6\n2\nGas\n30\n\n\nC\n8\n2\nGas\n30\n\n\nD\n7\n3\nGas\n40\n\n\nE\n6\n2\nElec\n40\n\n\nF\n7\n2\nHyb\n35\n\n\n\n\n# Attributes matrix for the minivans\nminivans = np.array([\n    [1, 0, 0, 1, 0, 30],  # Minivan A: 7 seats, 2ft cargo, Hybrid, $30k\n    [0, 0, 0, 0, 0, 30],  # Minivan B: 6 seats, 2ft cargo, Gas, $30k\n    [0, 1, 0, 0, 0, 30],  # Minivan C: 8 seats, 2ft cargo, Gas, $30k\n    [1, 0, 1, 0, 0, 40],  # Minivan D: 7 seats, 3ft cargo, Gas, $40k\n    [0, 0, 0, 0, 1, 40],  # Minivan E: 6 seats, 2ft cargo, Electric, $40k\n    [1, 0, 0, 1, 0, 35]   # Minivan F: 7 seats, 2ft cargo, Hybrid, $35k\n])\n\n# Coefficients array corresponding to Seat_7, Seat_8, Cargo_3ft, Eng_hyb, Eng_elec, and price\nbeta = np.array([-0.2968, -0.0780, 0.5387, -0.5356, -1.1532, -0.0112])\n\n# Calculate utilities for each minivan\nutilities = np.dot(minivans, beta)\n\n# Calculate probabilities using the softmax function\nexp_utilities = np.exp(utilities)\nprobabilities = exp_utilities / exp_utilities.sum()\n\nprint(\"Market Shares for each Minivan:\", probabilities)\n\nMarket Shares for each Minivan: [0.10376561 0.23853942 0.22064048 0.2716283  0.06731174 0.09811444]"
  },
  {
    "objectID": "projects/project 1/hw4_questions.html",
    "href": "projects/project 1/hw4_questions.html",
    "title": "Key Drivers Analysis",
    "section": "",
    "text": "This post implements a few measure of variable importance, interpreted as a key drivers analysis, for certain aspects of a payment card on customer satisfaction with that payment card.\ntodo: replicate the table on slide 19 of the session 4 slides. This involves calculating pearson correlations, standardized regression coefficients, “usefulness”, Shapley values for a linear regression, Johnson’s relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into R or Python.\nimport pandas as pd\n\n# Load the dataset\ndata_path = '../../files/data_for_drivers_analysis.csv'\ndata = pd.read_csv(data_path)\n\n# Display the first few rows of the dataframe to inspect the columns\ndata.head(), data.columns\n\n(   brand   id  satisfaction  trust  build  differs  easy  appealing  \\\n 0      1   98             3      1      0        1     1          1   \n 1      1  179             5      0      0        0     0          0   \n 2      1  197             3      1      0        0     1          1   \n 3      1  317             1      0      0        0     0          1   \n 4      1  356             4      1      1        1     1          1   \n \n    rewarding  popular  service  impact  \n 0          0        0        1       0  \n 1          0        0        0       0  \n 2          1        0        1       1  \n 3          0        1        1       1  \n 4          1        1        1       1  ,\n Index(['brand', 'id', 'satisfaction', 'trust', 'build', 'differs', 'easy',\n        'appealing', 'rewarding', 'popular', 'service', 'impact'],\n       dtype='object'))\nThe dataset contains the following columns that map to the perceptions identified on the slide:\ntrust: Is offered by a brand I trust\nbuild: Helps build credit quickly\ndiffers: Is different from other cards\neasy: Is easy to use\nappealing: Has appealing benefits or rewards\nrewarding: Rewards me for responsible usage\npopular: Is used by a lot of people\nservice: Provides outstanding customer service\nimpact: Makes a difference in my life"
  },
  {
    "objectID": "projects/project 1/hw4_questions.html#key-driver-analysis",
    "href": "projects/project 1/hw4_questions.html#key-driver-analysis",
    "title": "Key Drivers Analysis",
    "section": "Key Driver Analysis",
    "text": "Key Driver Analysis\n\n\n\n\n\n\n\n\n\n\nPerception\nPearson Correlations (%)\nStandardized Regression Coefficients (%)\nLMG / Shapley Values (Johnson’s Epsilon) (%)\nMean Decrease in RF Gini Coefficient (%)\n\n\n\n\nIs offered by a brand I trust\n25.6\n11.6\n0.82\n15.5\n\n\nHelps build credit quickly\n19.2\n2.0\n0.03\n10.0\n\n\nIs different from other cards\n18.5\n2.8\n0.06\n9.2\n\n\nIs easy to use\n21.3\n2.2\n0.03\n10.1\n\n\nHas appealing benefits or rewards\n20.8\n3.4\n0.07\n8.3\n\n\nRewards me for responsible usage\n19.5\n0.5\n0.002\n10.1\n\n\nIs used by a lot of people\n17.1\n1.7\n0.02\n9.8\n\n\nProvides outstanding customer service\n25.1\n8.8\n0.47\n13.3\n\n\nMakes a difference in my life\n25.5\n12.8\n1.12\n13.7"
  },
  {
    "objectID": "projects/project 1/hw4_questions.html#conclusion",
    "href": "projects/project 1/hw4_questions.html#conclusion",
    "title": "Key Drivers Analysis",
    "section": "Conclusion",
    "text": "Conclusion\nThe analysis highlights that perceptions related to trust in the brand, the impact of the card on the user’s life, and outstanding customer service are most strongly associated with customer satisfaction.\nIf you want a challenge, either (1) implement one or more of the measures yourself. “Usefulness” is rather easy to program up. Shapley values for linear regression are a bit more work. Or (2) add additional measures to the table such as the importance scores from XGBoost."
  }
]